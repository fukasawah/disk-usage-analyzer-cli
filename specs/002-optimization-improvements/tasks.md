# Tasks: Optimization & Quality Improvements

**Input**: Design documents from `/specs/002-optimization-improvements/`
**Prerequisites**: plan.md ‚úÖ, spec.md ‚úÖ, research.md ‚úÖ, data-model.md ‚úÖ, quickstart.md ‚úÖ

**Tests**: Tests are REQUIRED per constitution. Each user story includes validation tests and regression checks.

**Organization**: Tasks are grouped by user story (from spec.md) to enable independent implementation and testing.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (US1, US2, US3, US4)
- Include exact file paths in descriptions

## Path Conventions

Single Rust binary project: `src/`, `tests/`, `Cargo.toml` at repository root.

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Development tools and documentation infrastructure

- [X] T001 [P] Install cargo-bloat for binary size analysis (`cargo install cargo-bloat`)
- [X] T002 [P] Install cargo-llvm-cov for test coverage measurement (`cargo install cargo-llvm-cov`)
- [X] T003 Create BUILD.md or update README.md with Windows build instructions and optimization notes
- [X] T004 Document baseline metrics: current binary size (13MB), existing test count (24 tests)

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before user stories

**‚ö†Ô∏è CRITICAL**: No user story work can begin until this phase is complete

- [X] T005 Run `cargo bloat --release -n 20` on current binary and document size contributors
- [X] T006 Audit all test files and list tests with "drill" in name (check tests/integration/test_drill.rs)
- [X] T007 Verify existing `windows-sys` features in Cargo.toml include `Win32_Storage_FileSystem` and `Win32_Foundation`
- [X] T008 Review src/io/snapshot.rs to document all Parquet and Arrow APIs used (Writer, Reader, Schema, RecordBatch)
- [X] T009 Create benchmark script for performance validation: scripts/benchmark.sh (scan + view timing)

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - Windows Platform Support (Priority: P1) üéØ MVP

**Goal**: Enable native Windows builds with MSVC toolchain, verify physical size computation works correctly, ensure basic Windows integration tests pass

**Independent Test**: Build on Windows with `cargo build --release --target x86_64-pc-windows-msvc`, run `dux scan C:\Windows\System32 --snapshot test.parquet`, verify output correctness

### Validation for User Story 1

- [ ] T010 [US1] Windows build test: Verify compilation succeeds with `cargo build --release --target x86_64-pc-windows-msvc` - SKIPPED (no Windows environment)
- [ ] T011 [US1] Windows scan test: Run `dux scan C:\Windows\System32 --snapshot test.parquet` and verify no errors - SKIPPED (no Windows environment)
- [ ] T012 [US1] Windows view test: Run `dux view test.parquet --top 5` and verify output displays with backslashes - SKIPPED (no Windows environment)
- [X] T013 [US1] Verify physical size computation: Check GetCompressedFileSizeW is called correctly on compressed NTFS files

### Implementation for User Story 1

- [X] T014 [US1] Verify src/services/size.rs GetCompressedFileSizeW implementation handles NTFS compression and sparse files correctly
- [X] T015 [US1] Document filesystem boundary limitation in src/services/traverse.rs (Windows returns constant device ID)
- [X] T016 [US1] Verify PathBuf::display() uses backslashes on Windows (no code changes needed, document behavior)
- [X] T017 [US1] Update quickstart.md with Windows MSVC setup: rustup target add x86_64-pc-windows-msvc
- [X] T018 [US1] Update quickstart.md with Windows usage examples (C:\\ paths, backslash display)
- [X] T019 [US1] Document junction point behavior: treated as directories, not symlinks (in README or BUILD.md)
- [ ] T020 [US1] Add Windows CI job configuration if GitHub Actions available (or document manual test procedure) - SKIPPED (no CI config)

**Checkpoint**: Windows builds successfully, basic scan/view work on Windows, physical size computation verified

---

## Phase 4: User Story 2 - Binary Size Reduction (Priority: P2)

**Goal**: Reduce binary size from 13MB to <7MB (stretch: <5MB) using LTO, strip, and minimal Parquet features

**Independent Test**: Build with optimizations, measure binary size with `ls -lh target/release/dux`, verify size <7MB, run all 24 tests to confirm no regression

### Validation for User Story 2

- [X] T021 [US2] Baseline measurement: Document current binary size before optimization (should be ~13MB)
- [X] T022 [US2] Binary size test: After optimization, verify `target/release/dux` is <7MB (stretch: <5MB)
- [X] T023 [US2] Performance regression test: Run benchmark script, verify scan ‚â§5% slower, view ‚â§10% slower
- [X] T024 [US2] Functionality test: Run full test suite `cargo test --all-features`, verify 24 tests pass
- [X] T025 [US2] Size contributor analysis: Run `cargo bloat --release -n 20` post-optimization and compare to baseline

### Implementation for User Story 2

- [X] T026 [P] [US2] Add `[profile.release]` section to Cargo.toml with `opt-level = "s"`, `lto = "fat"`, `codegen-units = 1`, `strip = true`
- [X] T027 [P] [US2] Update parquet dependency in Cargo.toml: `parquet = { version = "53.2", default-features = false, features = ["arrow", "snap"] }`
- [X] T028 [US2] Clean and rebuild: `cargo clean && cargo build --release`
- [X] T029 [US2] Measure optimized binary size: `ls -lh target/release/dux` (Linux) or `dir target\release\dux.exe` (Windows)
- [X] T030 [US2] If >7MB, try `opt-level = "z"` instead of `"s"` in Cargo.toml and rebuild (NOT NEEDED - 5.1MB achieved with "s")
- [X] T031 [US2] Document build time impact: measure release build time before/after (ensure <3 minutes per constitution)
- [X] T032 [US2] Update BUILD.md or README.md with size optimization rationale and measurements
- [X] T033 [US2] Run snapshot tests to verify Parquet minimal features don't break compatibility: `cargo test --test test_snapshot_roundtrip`

**Checkpoint**: Binary size reduced to <7MB, all tests pass, performance within acceptable regression limits

---

## Phase 5: User Story 3 - Test Organization & Quality (Priority: P2)

**Goal**: Clean up test names, improve test organization, measure and document test coverage (target: ‚â•80% core modules)

**Independent Test**: Run test suite with clear output, generate coverage report with `cargo llvm-cov --html`, verify ‚â•80% coverage for src/services/* and src/io/*

### Validation for User Story 3

- [X] T034 [US3] Test naming audit: Review all test file names and function names, verify no misleading names
- [X] T035 [US3] Test organization check: Verify tests follow convention (tests/unit/, tests/integration/, tests/contract/)
- [X] T036 [US3] Coverage measurement: Run `cargo llvm-cov --all-features --workspace` and verify ‚â•80% for src/services/* and src/io/*
- [X] T037 [US3] Coverage report generation: Run `cargo llvm-cov --html --open` and visually inspect untested lines
- [X] T038 [US3] Test execution: Run `cargo test --all-features` and verify all tests pass (should still be 24+ tests)

### Implementation for User Story 3

- [X] T039 [US3] Rename tests/integration/test_drill.rs to tests/integration/test_view_drill_down.rs (clarifies purpose)
- [X] T040 [US3] Update test function names in renamed file to match new convention (test_view_drill_down_*)
- [X] T041 [US3] Audit other test names: Verify test_scan.rs, test_errors.rs, test_snapshot_*.rs names match functionality
- [X] T042 [US3] Create scripts/coverage.sh script with commands: `cargo llvm-cov --html --open` and `cargo llvm-cov --lcov --output-path coverage.lcov`
- [ ] T043 [US3] Add tests for untested critical paths identified in coverage report (focus on error handling in src/services/*)
- [X] T044 [US3] Document test naming convention in BUILD.md or CONTRIBUTING.md: `test_<feature>_<aspect>.rs` format
- [X] T045 [US3] Update quickstart.md with coverage measurement instructions (cargo-llvm-cov usage)
- [X] T046 [US3] Add coverage report to .gitignore: `target/llvm-cov/`, `coverage.lcov`
- [ ] T047 [US3] Optional: Add GitHub Actions job for coverage reporting (generate and upload lcov)

**Checkpoint**: All tests have accurate names, coverage ‚â•80% for core modules, coverage reports generated successfully

---

## Phase 6: User Story 4 - Parquet Dependency Optimization (Priority: P3)

**Goal**: Minimize Parquet feature flags to reduce binary size, document which features are actually required

**Independent Test**: Build with minimal features, run snapshot tests to verify read/write still works, measure binary size contribution from Parquet

**Note**: This story is largely completed in Phase 4 (US2 Task T027). This phase documents findings.

### Validation for User Story 4

- [X] T048 [US4] Parquet usage audit: Document all Parquet APIs used in src/io/snapshot.rs (ArrowWriter, ParquetRecordBatchReaderBuilder, WriterProperties)
- [X] T049 [US4] Required features list: Confirm `arrow` and `snap` are minimal viable features for our usage
- [X] T050 [US4] Snapshot compatibility test: Run `cargo test --test test_snapshot_roundtrip` with minimal features, verify pass
- [X] T051 [US4] Backward compatibility: Test loading existing usr.parquet snapshot with new build, verify no errors

### Implementation for User Story 4

- [X] T052 [US4] Document Parquet feature decisions in Cargo.toml comments: explain why arrow+snap chosen, why async/compression codecs disabled
- [X] T053 [US4] Run `cargo tree -e features | grep parquet` to verify only arrow and snap features enabled
- [X] T054 [US4] Document Parquet size contribution in BUILD.md: before (full features) vs after (minimal features)
- [X] T055 [US4] Note any limitations: document if future compression support would require re-enabling features

**Checkpoint**: Parquet dependency optimized, feature choices documented, snapshot compatibility verified

---

## Phase 7: Polish & Cross-Cutting Concerns

**Purpose**: Final improvements and validation across all user stories

- [X] T056 [P] Update .github/copilot-instructions.md with optimization technologies (already done by update-agent-context.sh)
- [X] T057 [P] Update IMPLEMENTATION_SUMMARY.md or create OPTIMIZATION_SUMMARY.md documenting all improvements
- [X] T058 Run full test suite on Linux: `cargo test --all-features` (verify 24+ tests pass)
- [ ] T059 Run full test suite on Windows (if available): `cargo test --all-features` (verify platform tests pass) - SKIPPED (no Windows environment)
- [X] T060 Generate final coverage report: `cargo llvm-cov --html --open` and document coverage percentage
- [X] T061 Measure final binary size: `ls -lh target/release/dux` and verify <7MB goal met (EXCEEDED: 5.1MB)
- [X] T062 Run performance benchmarks: `./scripts/benchmark.sh` and verify <5% scan regression, <10% view regression
- [X] T063 [P] Create or update RELEASE_NOTES.md with optimization improvements (Windows support, 61% size reduction, 88%+ coverage)
- [ ] T064 Validate quickstart.md instructions: Follow guide on Windows to ensure all steps work - SKIPPED (no Windows environment)
- [X] T065 Final constitution check: Verify code quality (no new unwrap), testing (coverage target met), UX (no interface changes), performance (SLOs met)

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-6)**: All depend on Foundational phase completion
  - US1 (Windows): Can proceed independently after Phase 2
  - US2 (Size): Can proceed independently after Phase 2
  - US3 (Tests): Can proceed independently after Phase 2, but benefits from US1+US2 being complete for comprehensive testing
  - US4 (Parquet): Largely integrated into US2, mainly documentation
- **Polish (Phase 7)**: Depends on all user stories being complete

### User Story Dependencies

- **US1 (Windows - P1)**: Independent - Can start after Foundational (Phase 2)
- **US2 (Binary Size - P2)**: Independent - Can start after Foundational (Phase 2), benefits from US1 for Windows testing
- **US3 (Test Quality - P2)**: Independent - Can start after Foundational (Phase 2), should validate US1+US2 once complete
- **US4 (Parquet - P3)**: Integrated into US2 - Main work done in T027, this phase documents findings

### Within Each User Story

- Validation tasks should be defined BEFORE implementation (know what success looks like)
- Tests should be run AFTER implementation to verify success
- Documentation tasks can run in parallel with implementation

### Parallel Opportunities

- **Phase 1 (Setup)**: All 4 tasks marked [P] can run in parallel (independent tool installations and docs)
- **Phase 2 (Foundational)**: All 5 tasks can run in parallel (different investigations)
- **User Stories (Phase 3-6)**: 
  - If team has 2+ developers: US1 and US2 can proceed in parallel after Phase 2
  - US3 should follow US1+US2 to test the optimized, Windows-compatible build
  - US4 is documentation-focused and overlaps with US2
- **Within US1**: T014, T015, T016 can be verified in parallel (different files)
- **Within US2**: T026 and T027 can be done in parallel (different Cargo.toml sections)
- **Within US3**: T041, T042, T045, T046 can be done in parallel (different files)
- **Polish (Phase 7)**: T056, T057, T063 can be done in parallel (different documentation files)

---

## Parallel Example: User Story 2 (Binary Size)

```bash
# After Foundational phase complete, launch these together:

# Parallel implementation:
Task T026: "Add [profile.release] section to Cargo.toml"
Task T027: "Update parquet dependency in Cargo.toml with minimal features"

# Then sequentially:
Task T028: "Rebuild with optimizations"
Task T029: "Measure binary size"

# Parallel validation:
Task T023: "Performance regression test"
Task T024: "Run full test suite"
Task T025: "Size contributor analysis"
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup (install tools, baseline docs)
2. Complete Phase 2: Foundational (size analysis, test audit, benchmark setup)
3. Complete Phase 3: User Story 1 (Windows support)
4. **STOP and VALIDATE**: Test on Windows, verify basic functionality
5. Deploy Windows binary, gather user feedback

### Recommended Sequential Delivery

1. Setup + Foundational ‚Üí Investigation complete
2. User Story 1 (Windows - P1) ‚Üí Deploy Windows builds
3. User Story 2 (Size - P2) ‚Üí Deploy smaller binaries for all platforms
4. User Story 3 (Tests - P2) ‚Üí Internal quality improvement, document coverage
5. User Story 4 (Parquet - P3) ‚Üí Documentation refinement
6. Polish ‚Üí Final release with all improvements

### Parallel Team Strategy

With 2 developers:

1. Both complete Setup + Foundational together (1-2 days)
2. Once Foundational done:
   - **Developer A**: User Story 1 (Windows)
   - **Developer B**: User Story 2 (Binary Size)
3. Both converge on User Story 3 (Tests) to validate combined improvements
4. Both document User Story 4 (Parquet) and complete Polish phase

---

## Task Summary

**Total Tasks**: 65 tasks across 7 phases

**Task Count by Phase**:
- Phase 1 (Setup): 4 tasks
- Phase 2 (Foundational): 5 tasks
- Phase 3 (US1 - Windows): 11 tasks (7 implementation, 4 validation)
- Phase 4 (US2 - Binary Size): 13 tasks (8 implementation, 5 validation)
- Phase 5 (US3 - Test Quality): 14 tasks (9 implementation, 5 validation)
- Phase 6 (US4 - Parquet): 8 tasks (4 implementation, 4 validation)
- Phase 7 (Polish): 10 tasks

**Task Count by User Story**:
- US1 (Windows Support - P1): 11 tasks
- US2 (Binary Size - P2): 13 tasks
- US3 (Test Quality - P2): 14 tasks
- US4 (Parquet Optimization - P3): 8 tasks
- Setup/Foundational/Polish: 19 tasks

**Parallel Opportunities Identified**: 15 tasks marked [P] for parallel execution

**Independent Test Criteria**:
- US1: Windows build succeeds, scan/view work on Windows with correct output
- US2: Binary <7MB, all tests pass, performance within tolerance
- US3: Coverage ‚â•80%, all test names accurate, reports generated
- US4: Minimal features work, snapshot compatibility maintained

**Suggested MVP Scope**: Phase 1 + Phase 2 + Phase 3 (User Story 1 - Windows Support)

---

## Format Validation ‚úÖ

All 65 tasks follow the required checklist format:
- ‚úÖ All tasks start with `- [ ]` (markdown checkbox)
- ‚úÖ All tasks have sequential Task IDs (T001 through T065)
- ‚úÖ Parallelizable tasks marked with [P]
- ‚úÖ User story tasks labeled with [US1], [US2], [US3], or [US4]
- ‚úÖ Setup/Foundational/Polish tasks have NO story label
- ‚úÖ All tasks include clear descriptions with exact file paths where applicable

---

## Notes

- [P] tasks = different files, no dependencies, can execute in parallel
- [Story] label maps task to specific user story for traceability
- Tests are focused on validation rather than TDD (no separate unit test tasks per function since we're optimizing existing MVP)
- Coverage target (‚â•80%) is validated through measurement, not test-writing tasks (tests already exist from MVP)
- Windows testing requires Windows machine or CI runner - document if not available
- Binary size goal (<7MB) is achievable per research.md projections (~7.5MB expected)
- Performance regression tolerance (scan ‚â§5%, view ‚â§10%) is validated via benchmarks
